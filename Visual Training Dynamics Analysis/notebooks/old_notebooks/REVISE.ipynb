{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "REVISE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FahuzxGUYuVB"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which conda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbkRoG4tZhtg",
        "outputId": "fd4f4751-b856-4ebb-ea20-c016b3b53eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/conda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LADlB-m-Zn7N",
        "outputId": "3b8c6a53-e7a9-42f9-c6bf-fe606a2449eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 4.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "conda install --channel defaults conda python=3.6 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "metadata": {
        "id": "t1vecQ7zZsc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQVJN3IpaK4S",
        "outputId": "5c9c31da-66c0-4509-d2d5-fa2912e1984d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 4.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path"
      ],
      "metadata": {
        "id": "P2sMDd-VaQNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env create -f environment.yml"
      ],
      "metadata": {
        "id": "WrKf70faa2aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash \n",
        "download.sh"
      ],
      "metadata": {
        "id": "SedkhooheDn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def obj_cnt(dataloader, args):\n",
        "    counts = {}\n",
        "    all_categories = dataloader.dataset.categories\n",
        "    for i in range(len(all_categories)):\n",
        "        counts[\"{0}-{1}\".format(i, i)] = 0\n",
        "        for j in range(i+1, len(all_categories)):\n",
        "            counts[\"{0}-{1}\".format(i, j)] = 0\n",
        "\n",
        "    groupings_size = [[] for i in range(len(dataloader.dataset.supercategories_to_names))]\n",
        "    groupings_dist = [[] for i in range(len(dataloader.dataset.supercategories_to_names))]\n",
        "    group_mapping = dataloader.dataset.group_mapping\n",
        "    img_center = np.array([.5, .5])\n",
        "    instances_size = [[] for i in range(len(all_categories))]\n",
        "\n",
        "    filepaths = [[] for i in range(len(dataloader.dataset.supercategories_to_names))] # for qualitative examples in analysis step\n",
        "\n",
        "    with_people_instances = np.zeros(len(all_categories))\n",
        "    with_people = np.zeros(len(dataloader.dataset.supercategories_to_names))\n",
        "    not_with_people = np.zeros(len(dataloader.dataset.supercategories_to_names))\n",
        "    if hasattr(dataloader.dataset, 'people_labels'):\n",
        "        people = dataloader.dataset.people_labels\n",
        "    else:\n",
        "        people = None\n",
        "\n",
        "    overlap = {}\n",
        "    overlap_percent = .95\n",
        "\n",
        "    for i, (data, target) in enumerate(tqdm(dataloader)):\n",
        "        anns = target[0]\n",
        "        filepath = target[3]\n",
        "        categories = list(set([ann['label'] for ann in anns]))\n",
        "        if people is not None:\n",
        "            has_people = False\n",
        "            if len(list(set(people) & set(categories))) > 0:\n",
        "                has_people = True\n",
        "\n",
        "        co_added = []\n",
        "        overlap_added = []\n",
        "        people_added = []\n",
        "        sizes_added = []\n",
        "        for a in range(len(anns)):\n",
        "            \n",
        "            bbox = anns[a]['bbox']\n",
        "            size = (bbox[1]-bbox[0])*(bbox[3]-bbox[2])\n",
        "            if anns[a]['label'] not in sizes_added:\n",
        "                instances_size[all_categories.index(anns[a]['label'])].append([size, filepath])\n",
        "                sizes_added.append(anns[a]['label'])\n",
        "            elif instances_size[all_categories.index(anns[a]['label'])][-1][0] < size:\n",
        "                instances_size[all_categories.index(anns[a]['label'])][-1][0] = size\n",
        "            if group_mapping is not None:\n",
        "                # size of object and distance of object from image center\n",
        "                group = group_mapping(anns[a]['label'])\n",
        "                obj_center = np.array([bbox[0] + (bbox[1]/2.), bbox[2] + (bbox[3]/2.)])\n",
        "                distance = np.linalg.norm(obj_center - img_center)\n",
        "                groupings_size[group].append(size)\n",
        "                groupings_dist[group].append(distance)\n",
        "\n",
        "                # if there's a person in this image or not\n",
        "                if people is not None:\n",
        "                    if group not in people_added:\n",
        "                        if len(filepaths[group]) < 500:\n",
        "                            filepaths[group].append(filepath)\n",
        "\n",
        "                        if has_people:\n",
        "                            with_people[group] += 1\n",
        "                        else:\n",
        "                            not_with_people[group] += 1\n",
        "                        people_added.append(group)\n",
        "\n",
        "            # instance and cooccurrence counts\n",
        "            cat_a = dataloader.dataset.categories.index(anns[a]['label'])\n",
        "            key = '{0}-{1}'.format(cat_a, cat_a)\n",
        "            if key not in co_added:\n",
        "                co_added.append(key)\n",
        "                counts[key] += 1\n",
        "                if people is not None and has_people:\n",
        "                    with_people_instances[cat_a] += 1\n",
        "            for b in range(a+1, len(anns)):\n",
        "                cat_b = dataloader.dataset.categories.index(anns[b]['label'])\n",
        "                if cat_a < cat_b:\n",
        "                    key = \"{0}-{1}\".format(cat_a, cat_b)\n",
        "                else:\n",
        "                    key = \"{0}-{1}\".format(cat_b, cat_a)\n",
        "                if 'bbox' in anns[a].keys() and bb_intersection_over_union(anns[a]['bbox'], anns[b]['bbox']) > overlap_percent and anns[a]['label'] != anns[b]['label']:\n",
        "                    if key not in overlap_added:\n",
        "                        overlap_added.append(key)\n",
        "                        if key in overlap.keys():\n",
        "                            overlap[key] += 1\n",
        "                        else:\n",
        "                            overlap[key] = 1\n",
        "                if key not in co_added:\n",
        "                    co_added.append(key)\n",
        "                    counts[key] += 1\n",
        "\n",
        "    stats = {}\n",
        "    stats['counts'] = counts\n",
        "    stats['overlap'] = overlap\n",
        "    stats['sizes'] = groupings_size\n",
        "    stats['distances'] = groupings_dist\n",
        "    stats['with_people'] = with_people\n",
        "    stats['not_with_people'] = not_with_people\n",
        "    stats['with_people_instances'] = with_people_instances\n",
        "    stats['filepaths'] = filepaths\n",
        "    stats['instances_size'] = instances_size\n",
        "    pickle.dump(stats, open(\"results/{}/obj_cnt.pkl\".format(args.folder), \"wb\"))"
      ],
      "metadata": {
        "id": "B7eyqzZiOlTP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}